---
title: "STAT343 - Project"
author: "Hye Woong Jeon, Rohan Kapoor"
date: ""
output:
  html_document: 
    keep_md: yes
  pdf_document: default
fontsize: 11pt
abstract: ""
---

```{r include = FALSE}
library(glmnet)
library(MASS)
```

### Decision list

* For types, delete the entries that are ambiguous. For example, the ones that are like "Blade (Flake?)" or "Core fragment? Flake?". Reason: if labeled ambiguously, we will never know the "correct" label, and if we decide to coerce into one of the levels by looking at the data, then we are introducing selective inference problems. We only lose 9 data points (original: 652, modified: 643) - APPROVED

* For site, delete the two sites that are not Ali Kosh and Chagha Sefid. Reason: the label is ambiguous for the Ali Kosh / Chagha Sefid point, and for the Tepe point, there's only one point so it's not like we could derive any useful insights regarding that site anyway. We only lose two data points (original: 643, modified: 641) - APPROVED





In this project, we will analyze a dataset on Obsidian rocks, and try to build a working linear model for predicting the mass of a rock made of obsidian. 

Step 0: Importing the data and looking at it, trying to get a feel for it. 

```{r}
data <- read.table("data/obsidian_data.txt", header = TRUE, sep = ",")
```

```{r}
head(data, n=10)
```

Data looks like it made it into R okay, so we can start analyzing it. 

Step 1: Data Exploration, cleaning, dealing with missing data. 

```{r}
summary(data)
```

Already, we spot some interesting features: we see a repeated ID, making me suspect an object has been logged twice. There seems to be a missing mass value, as well a terribly wrong outlier on the high side. A few missing and a few uncertain types. An ambigious site which we should probably predict. Element Rb and Element Sr look fine, but Element Y seems to have an outlier on the high side, and Element Zr has a low side outlier. Let's look at these one by one. 


```{r}
data[which(data$ID == "288275.002bh"), ]
```
This just looks like a double-logged entry, so I will simply delete it. 

```{r}

data <- data[-33,]
#commenting out so I do not run it again, but I ran it once. 
```
Now let us look at mass. I spot a few ourliers, so I will try to look at those. 
The 160 value is an order of magntude above anything else, so I just get rid of it, since I cannot fill in the value in any way.

```{r}
data[which(data$mass >= 10), ]
#data[which(data$mass == NA), ] #no null values returned. 
```

```{r}
data <- data[-464,]
#commenting out so I do not run it again, but I ran it once. 
```
I also get rid of the NA value for mass, since I cannot impute for the regression output anyway


Now I plot the histogram of masses to see what kind of distribution it follows. 
```{r}
hist(data$mass)
```
Clearly, this does not seem normal It might be worth putting some sort of transformation onto it: probably transforming it on a log scale, or other variable. We will see about this later, but take a note of this. 

```{r}
hist(log(data$mass))
```
This looks pretty good so let's do it

```{r}
data$mass <- log(data$mass)
```


We should combine some of the type variables: blade and blades, etc. I feel pretty comfortable doing this, since all the errors seem to be for similar objects not and just logged differently by one person. 
Even if it is not perfect, it seems necessary to do since we cannot deal with that large a number of different types and simplifying to 2-3 kinds of terms helps us save degrees of freedom for other considerations later.
I first considered Retouched Blades being a different category to blades, but there are only 3 data points, which means even if they are differnet, they won't contribute much to a differnt effect, so I should just combine with Blade. Same with Used Flake to Flake.
```{r}
levels(data$type)
```

```{r}
# data$type[data$type == "Blades"] <- "Blade"
# data$type[data$type == "blade"] <- "Blade"
# data$type[data$type == "Distal end of prismatic blade?"] <- "Blade"
# 
# data$type[data$type == "flake"] <- "Flake"
# data$type[data$type == "Flakes"] <- "Flake"
# data$type[data$type == "Flake (listed as)"] <- "Flake"
# 
# data$type[data$type == "core"] <- "Core"
# data$type[data$type == "Cores and frags"] <- "Core"
# data$type[data$type == "Core/Fragment"] <- "Core"
# data$type[data$type == "Core fragment"] <- "Core"
# data$type[data$type == "Core fragment?"] <- "Core"
# data$type[data$type == "Cores and fragments"] <- "Core"
# data$type[data$type ==  "Fragment (from core?)"] <- "Core"
# 
# data$type[data$type == "Retouched blades"] <- "Retouched Blade" 
# data$type[data$type == "Retouched Blades"] <- "Retouched Blade"     
# 
# data$type[data$type == "Retouched Blade"] <- "Blade" 
# data$type[data$type == "Used flake"] <- "Flake" 

data <- data[-which(data$type ==  "Blade (Flake?)"),]
data <- data[-which(data$type ==  "Core fragment? Flake?"),]
data <- data[-which(data$type ==  "Fragment (from core?)"),]

blade_type = c(
  "Blade", 
  "Distal end of prismatic blade?",
  "Blades",
  "Retouched blades",
  "Retouched Blade",
  "blade",
  "Retouched Blades"
)
flake_type = c(
  "Flake (listed as)",
  "flake",
  "Flake",
  "Used flake",
  "Flakes"
)
core_type = c(
  "Core fragment?",
  "Core fragment",
  "Fragment (from core?)",
  "Core",
  "Cores and frags",
  "core",
  "Cores and fragments",
  "Core/Fragment"
)

blade_data = data[which(data$type %in% blade_type),]
flake_data = data[which(data$type %in% flake_type),]
core_data = data[which(data$type %in% core_type),]

blade_data$type = "Blade"
flake_data$type = "Flake"
core_data$type = "Core"

data = rbind(blade_data, flake_data, core_data)
```

```{r}
unique(data$type)
```

Also, we drop the NA entry in mass or type

```{r}
data <- data[complete.cases(data[, c('mass', 'type')]), ]
```



Now for the two site outliers. 
```{r}
data <- data[-which(data$site == "Ali Kosh/Chaga Sefid" | data$site == "Hulailan Tepe Guran"), ]
```

<!-- For the first one, we know that we just need to pick Ali Kosh/Chaga Sefid as its location, which we will do by imputing by mean. For the latter, we can either get rid of it and restrict our model to two sites, or try to learn which site looks more like Hulailan Tepe Guran. I will opt to do the latter.  -->

Now I am just going to plot the histograms of the 4 elements and see what the distribution looks like. 

```{r}
hist(data$element_Rb)
hist(data$element_Sr)
hist(data$element_Y)
hist(data$element_Zr)
```

Rb looks fine, but I think the others have outliers we can get rid of, which are probably just mis-entered data. 

```{r}
data[which(data$element_Zr<100 | data$element_Y>50 | data$element_Sr<20), ]
```
I will just delete these two

```{r}
data <- data[-which(data$element_Zr<100 | data$element_Y>50 | data$element_Sr<20), ]
```

```{r}
summary(data)
```

The data looks clean-ish now. 

Note: note that we considered imputing by regression using a logistic regression model, but seemed too stenuous. 

<!-- So we move onto Step 3, inserting missing data or uncertain data. We have some NAs to fill in, as well as some uncertain types and sites which we will impute by mean. -->

<!-- For the sites, we see that the uncertain objects are both blades, so compare their masses to the masses of the blades found at the two common sites.  -->

<!-- ```{r} -->
<!-- mean(data[which(data$site == "Ali Kosh" & data$type == "Blade"), ]$mass) -->
<!-- mean(data[which(data$site == "Chagha Sefid" & data$type == "Blade"), ]$mass) -->
<!-- ``` -->
<!-- Both of the two uncertain sites seem closer to the mean of Ali Kosh, so I will reassign them there.  -->

<!-- ```{r} -->
<!-- data$site[data$site == "Ali Kosh/Chaga Sefid" | data$site == "Hulailan Tepe Guran"] <- "Ali Kosh" -->
<!-- ``` -->

<!-- Now, we do the same for the uncertain types.  -->


<!-- ```{r} -->
<!-- mean(data[which(data$type == "Blade"), ]$mass) -->
<!-- mean(data[which(data$type == "Flake"), ]$mass) -->
<!-- mean(data[which(data$type == "Core"), ]$mass) -->
<!-- ``` -->

<!-- ```{r} -->
<!-- data[which(data$type != "Blade" & data$type != "Flake" & data$type != "Core" ), ] -->
<!-- ``` -->
<!-- Manually assign them to the one their mean is closer to in the two choices.  -->

<!-- ```{r} -->
<!-- data$type[data$ID == "288275.002i"] <- "Flake" -->
<!-- data$type[data$ID == "288276c"] <- "Flake" -->
<!-- data$type[data$ID == "288276e"] <- "Flake" -->
<!-- data$type[data$ID == "288276f"] <- "Blade" -->
<!-- data$type[data$ID == "288284oL"] <- "Core" -->

<!-- ``` -->

<!-- With our missing/uncertain values imputed, let us look at the data for one last time. -->

```{r}
cat_covs = 3:4
cts_covs = 5:8

for (i in cat_covs) {
  data[, i] = as.factor(data[, i])
}

summary(data)
```

Looks good!

Next, we check the correlations among the continuous covariates. This can be further confirmed by plotting all the the continuous covariates against each other. Observe that all the continuous covariates are highly correlated with each other. This can be further confirmed by calculating the variance inflation factor of the design matrix restricted to the continuous covariates - the design matrix is clearly poorly conditioned. 

```{r, fi.height=8}
cor(data[, cts_covs])
plot(data[, cts_covs], pch=20 , cex=1.5 , col="#69b3a2")

# variance inflation factor
cts_matrix = data.matrix(data[,cts_covs])
eigenvals = eigen(t(cts_matrix) %*% cts_matrix)
sqrt(eigenvals$val[1]/eigenvals$val)
```



## Model Building

To avoid selective inference problems, we split the data into training, validation, and test sets. 

```{r}
set.seed(2)

train_idx = sample(1:(dim(data)[1]), size=0.7*dim(data)[1])
train = data[train_idx,]
not_train = data[-train_idx,]
validate_idx = sample(1:(dim(not_train)[1]), size=0.5*dim(not_train)[1])
val = not_train[-validate_idx, ]
test = not_train[validate_idx,]
```

We first fit a simple model with no interaction terms. We cycle the order of the covariates in order to ask whether the categorical covariates are significant when compared against the full model. From the F-tests, we conclude that both the categorical covariates are significant in the full model i.e. there are significant differences between sites and also between object types.

The diagnostic plots signify that the model is reasonably good - in particular, the linearity and normality assumptions are reasonable, save for a few outliers in the QQ plot. However, the data appears to be heteroskedastic, as indicated by the sloped scale-location plot and the various diagnostic plots. 

```{r}
model0 = lm(formula = mass ~ element_Sr + element_Y + element_Rb + element_Zr + type + site, data=train)
anova(model0)

model0 = lm(formula = mass ~ element_Sr + element_Y + element_Rb + element_Zr + site + type, data=train)
anova(model0)
```

```{r, fig.height=8}
plot_diagnostics <- function(model, data) {
  par(mfrow=c(3,2))
  for (i in c(cat_covs, cts_covs)) {
    plot(data[, i], model$residuals, main=paste(colnames(data)[i], "vs. Residuals"))
  }
}

plot_model <- function(model) {
  par(mfrow=c(2,2))
  plot(model)
}

plot_diagnostics(model0, train)
```

```{r, fig.height=7}
par(mfrow=c(2,2))
plot(model0)
```

Due to the high collinearity among the continuous covariates, we consider eliminating some of the continuous covariates via sparsity-inducing methods such as lasso regression. We should also consider ridge regression because for its coefficient stability properties. 

```{r, eval=FALSE}
model1 = glmnet(train[, c(cat_covs, cts_covs)], y = train[, 2], lambda = seq(0, 0.1, 0.01))
betahat = rbind(model1$a0, as.matrix(model1$beta, nrow=6, ncol=8))

betahat
```

```{r}
model3 = lm.ridge(formula = mass ~ element_Sr + element_Y + element_Rb + element_Zr + type + site, data=train, lambda=seq(0,10,0.5))
coef(model3)
```

```{r, eval=TRUE, fig.height=8}
model2 = lm(mass ~ element_Rb + type + site, data=train)
summary(model2)
plot_diagnostics(model2, train)
plot_model(model2)
```


